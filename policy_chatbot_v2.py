import os
import streamlit as st
import openai
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import RetrievalQA

# âœ… API í‚¤ ì„¤ì •
openai.api_key = st.secrets["OPENAI_API_KEY"]
api_key = st.secrets["OPENAI_API_KEY"]

# âœ… ì œëª©ê³¼ ì„¤ëª…
st.title("ğŸ“„ ì²­ë…„ê³µì•½ ê¸°ë°˜ ì •ì±… ì±—ë´‡")
st.markdown("ğŸ’¬ PDF ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ GPTê°€ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")

# âœ… PDF ë¡œë”© ë° ì²˜ë¦¬
loader = PyPDFLoader("ì²­ë…„ê³µì•½.pdf")
pages = loader.load()

# âœ… í…ìŠ¤íŠ¸ ë¶„í• 
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = text_splitter.split_documents(pages)

# âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„±
embeddings = OpenAIEmbeddings(openai_api_key=st.secrets["OPENAI_API_KEY"])
db = FAISS.from_documents(texts, embeddings)

# âœ… ì§ˆì˜ì‘ë‹µ ì²´ì¸ êµ¬ì„±
qa = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(temperature=0, openai_api_key=api_key),
    chain_type="stuff",
    retriever=db.as_retriever()
)

# âœ… ì§ˆë¬¸ ì…ë ¥ë°›ê¸°
question = st.text_input("âœï¸ ê¶ê¸ˆí•œ ì •ì±… ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:")

if question:
    with st.spinner("GPTê°€ ì •ì±…ìë£Œë¥¼ ì½ê³  ë‹µë³€ ì¤‘..."):
        answer = qa.run(question)
        st.success(answer)
else:
    st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”")
