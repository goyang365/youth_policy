
import streamlit as st
import openai
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import RetrievalQA

# âœ… OpenAI API Key ì„¤ì •
openai.api_key = st.secrets["OPENAI_API_KEY"]
api_key = st.secrets["OPENAI_API_KEY"]

st.title("ğŸ“„ ì²­ë…„ê³µì•½ ê¸°ë°˜ ì •ì±… ì±—ë´‡")
st.markdown("ğŸ’¬ PDF ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ GPTê°€ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")

loader = PyPDFLoader("ì²­ë…„ê³µì•½.pdf")
pages = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = text_splitter.split_documents(pages)

embeddings = OpenAIEmbeddings(openai_api_key=api_key)
db = FAISS.from_documents(texts, embeddings)

qa = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(temperature=0, openai_api_key=api_key),
    chain_type="stuff",
    retriever=db.as_retriever()
)

question = st.text_input("âœï¸ ê¶ê¸ˆí•œ ì •ì±… ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:")

if question:
    with st.spinner("GPTê°€ ì •ì±…ìë£Œë¥¼ ì½ê³  ë‹µë³€ ì¤‘..."):
        answer = qa.run(question)
        st.success(answer)
else:
    st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”")
