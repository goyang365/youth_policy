
import streamlit as st
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA

# âœ… ë””ë²„ê·¸ ëª¨ë“œ ì—¬ë¶€ (Trueë©´ ì‹¤ì œ GPT í˜¸ì¶œ, Falseë©´ ëª¨ì˜ ì‘ë‹µ)
USE_OPENAI = False

st.title("ğŸ“„ ì²­ë…„ê³µì•½ ê¸°ë°˜ ì •ì±… ì±—ë´‡ (ë””ë²„ê·¸ ëª¨ë“œ)")
st.markdown("ğŸ’¬ PDF ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ GPTê°€ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤. (API ì—†ì´ í…ŒìŠ¤íŠ¸)")

# âœ… PDF ë¡œë”© ë° ì²˜ë¦¬
from pathlib import Path
pdf_path = Path(__file__).parent / "ì²­ë…„ê³µì•½.pdf"
loader = PyPDFLoader(str(pdf_path))
pages = loader.load()  # âœ… ì´ ì¤„ ê¼­ ìˆì–´ì•¼ í•´!

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = text_splitter.split_documents(pages)


if USE_OPENAI:
    import openai
    from langchain.chat_models import ChatOpenAI
    from langchain.embeddings import OpenAIEmbeddings

    openai.api_key = st.secrets["OPENAI_API_KEY"]
    api_key = st.secrets["OPENAI_API_KEY"]

    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    db = FAISS.from_documents(texts, embeddings)

    qa = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(temperature=0, openai_api_key=api_key),
        chain_type="stuff",
        retriever=db.as_retriever()
    )
else:
    qa = None

# âœ… ì§ˆë¬¸ ì…ë ¥
question = st.text_input("âœï¸ ê¶ê¸ˆí•œ ì •ì±… ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:")

if question:
    with st.spinner("GPTê°€ ì •ì±…ìë£Œë¥¼ ì½ê³  ë‹µë³€ ì¤‘..."):
        if USE_OPENAI and qa:
            answer = qa.run(question)
        else:
            answer = f"ğŸ’¡ [ëª¨ì˜ ì‘ë‹µ] '{question}' ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤. ì‹¤ì œ GPT ì—†ì´ í…ŒìŠ¤íŠ¸ ì¤‘ì…ë‹ˆë‹¤."
        st.success(answer)
else:
    st.info("í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸ì„ ì…ë ¥í•´ ë³´ì„¸ìš”.")
